\documentclass{in1150-innlevering}
\title{Report -- IN3200 Partial Exam, Spring 2019}
\author{Candidate No. 15220}
\date{\today}
\begin{document}
\maketitle
\begin{abstract}
	The main point of the program made in this project, is to list the top $n$ webpages of a given web graph using the \textbf{PageRank algorithm}.
\end{abstract}

\section*{Introduction}
\label{sec:introduction}
	A lot of information about the PageRank algorithm can be found online. The details necessary to understand this report are provided in the Partial Exam.\\
	\\
	The program has been written in C. This makes it fairly straightforward to parallelize parts of the code using Open MP. In order for this to work, our system must have shared memory.\\
	\\
	Given a web graph, a square hyperlink matrix can be set up. These are usually sparse (i.e. most elements are zero), giving huge potential for optimized storage. The storage scheme used in this project is the \emph{Compressed Row Storage} (CRS). Detailed information about CRS is available online. A good place to start is Wikipedia.

\section*{The functions}
\label{sec:the_functions}
	The core of the program consists of three functions: \texttt{read\_graph\_from\_file}, \texttt{PageRank\_iterations} and \texttt{top\_n\_webpages}.\\
	\\
	\texttt{read\_graph\_from\_file} stores a web graph in the CRS format. It also stores information about dangling webpages. It takes a string (the filename of the file containing the webgraph) as its only input and returns a CRS struct.\\
	\\The CRS struct is defined as folows:
	\begin{lstlisting}[language=C]
	struct CRS
	{
		int *row_ptr;
		int *col_idx;
		double *vals;
		int nodes;
		int nz;
		
		int *dangling_idx;
		int dangling_count;
	};
	\end{lstlisting}
	The three first entries should be self-explanatory for anyone familiar with CRS. Wise or not, the number of rows is stored as \texttt{nodes} (fourth entry), and the number of non-zero elements are stored as \texttt{nz} (fifth entry). The second to last entry holds the indices of the webpages with no outgoing links, so-called \emph{dangling webpages}, and the last entry simply holds the number of dangling webpages.\\
	\\
	\texttt{PageRank\_iterations} implements the iterative procedure of the PageRank algorithm -- please refer to the Partial Exam and comments in the code for details. It returns a converged PageRank score vector $\mathbf{x}$ of type double*. Its input arguments are the damping constant $d$, the convergence threshold $\upvarepsilon$ (eps) and a pointer to the CRS Struct made in the previous function.\\
	\\
	\texttt{top\_n\_webpages} prints the top $n$ webpages of a converged PageRank score vector along with their scores in the terminal. In this context the topmost webpages are those with the highest scores. The function does not return anything. It takes the number of webpages to display $n$, a converged PageRank vector $\mathbf{x}$ and the length of that vector \texttt{nodes} as input arguments.

\section*{Time measurements and hardware and compiler information}
\label{sec:time_measurements_and_hardware_and_compiler_information}
	The time measurements are presented in table \ref{tab:time}. The numbers were generated by running \texttt{time.exe}. More on this in the next section. The damping constant used was 0.85, the convergence threshold was 1e-15, the web graph was web-NotreDame.txt. These measurements give a rough idea of how a varying number of threads affects performance. The measurements were done quick and dirty, so the numbers are perhaps not exact to three decimal places as presented.
	\begin{table}
		\begin{center}
			\begin{tabular}{ll}
				\textbf{No. of threads} & \textbf{Time in seconds} \\
				1 & 1.423 \\
				2 & 0.870 \\
				3 & 0.691 \\
				4 & 0.562 \\
				5 & 0.935 \\
				6 & 0.903 \\
				7 & 0.742 \\
				8 & 0.692 \\
				12 & 0.865 \\
				24 & 1.210 \\
			\end{tabular}
			\caption{Time measurements of \texttt{PageRank\_iterations}.}
			\label{tab:time}
		\end{center}
	\end{table}
	The hardware information (Dell XPS 13, 8 GB RAM) is presented here:
	\begin{lstlisting}
	Architecture:        x86_64
	CPU op-mode(s):      32-bit, 64-bit
	Byte Order:          Little Endian
	CPU(s):              8
	On-line CPU(s) list: 0-7
	Thread(s) per core:  2
	Core(s) per socket:  4
	Socket(s):           1
	NUMA node(s):        1
	Vendor ID:           GenuineIntel
	CPU family:          6
	Model:               142
	Model name:          Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz
	Stepping:            10
	CPU MHz:             874.571
	CPU max MHz:         3400,0000
	CPU min MHz:         400,0000
	BogoMIPS:            3600.00
	Virtualization:      VT-x
	L1d cache:           32K
	L1i cache:           32K
	L2 cache:            256K
	L3 cache:            6144K
	NUMA node0 CPU(s):   0-7
	\end{lstlisting}
	Compiler: gcc (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0

\section*{Comments on the code}
\label{sec:misc}
	While writing the code, a program \texttt{test.exe} was used to verify the results. \texttt{test.exe} is compiled from \texttt{PE\_test\_15220.c}. This \texttt{.c}-file is included for the sake of completion, but keep in mind that it is not intended for others to read and understand outright.\\
	\\
	To do the time measurements with a varying number of OpenMP threads, a program \texttt{time.exe} compiled from \texttt{PE\_time\_15220.c} was used. Here, the function \texttt{PageRank\_iterations} is called a 15 times and an average time is given. This was done several times, varying the number of threads from one up to eight. Twelve and 24 threads are also included. Because the Partial Exam did not request a non-OpenMP version of the function, measurements of such a function are not included.\\
	\\
	A few comments on the details of the implentation of the functions are perhaps in order. In general, a sane and efficient implementation has been pursued to the best of my ability.

	In \texttt{read\_graph\_from\_file} the web graph is traversed twice: once for counting the number of outbound and inbound links from and to each webpage, then a second time to store the correct values in the CRS scheme. This seems sane.

	In \texttt{PageRank\_iterations} a lot of work is done in parallel. Using OpenMP, it is fairly simple to handle most issues that arises when working with multiple threads, e.g. the issue of race conditions. I believe there are no revolutionary optimizations in the code submitted, rather a sane straightforward implementation.

	The same goes for \texttt{top\_n\_webpages}; nothing out of the ordinary here.
	
\section*{Concluding remarks}
\label{sec:concluding_remarks}
	There are probably as many solutions to this project as there are people on earth, a lot of which are probably faster than the one submitted here. That said, the speed of this implementation is quite possibly sufficient for a lot of use cases.

\end{document}
